{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE 1: extract the list of hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_states_and_territories_of_the_United_States\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = requests.get(url)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(resp.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(doc.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = doc.find_all(\"table\")\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = None\n",
    "for t in tables:\n",
    "    if len(t.find_all(\"tr\")) >= 50:\n",
    "        table = t\n",
    "        break\n",
    "assert(table != None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "trs = table.find_all(\"tr\")\n",
    "print(len(trs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Alabama',\n",
       " 'https://en.wikipedia.org/wiki/Alaska',\n",
       " 'https://en.wikipedia.org/wiki/Arizona',\n",
       " 'https://en.wikipedia.org/wiki/Arkansas',\n",
       " 'https://en.wikipedia.org/wiki/California',\n",
       " 'https://en.wikipedia.org/wiki/Colorado',\n",
       " 'https://en.wikipedia.org/wiki/Connecticut',\n",
       " 'https://en.wikipedia.org/wiki/Delaware',\n",
       " 'https://en.wikipedia.org/wiki/Florida',\n",
       " 'https://en.wikipedia.org/wiki/Georgia_(U.S._state)',\n",
       " 'https://en.wikipedia.org/wiki/Hawaii',\n",
       " 'https://en.wikipedia.org/wiki/Idaho',\n",
       " 'https://en.wikipedia.org/wiki/Illinois',\n",
       " 'https://en.wikipedia.org/wiki/Indiana',\n",
       " 'https://en.wikipedia.org/wiki/Iowa',\n",
       " 'https://en.wikipedia.org/wiki/Kansas',\n",
       " 'https://en.wikipedia.org/wiki/Kentucky',\n",
       " 'https://en.wikipedia.org/wiki/Louisiana',\n",
       " 'https://en.wikipedia.org/wiki/Maine',\n",
       " 'https://en.wikipedia.org/wiki/Maryland',\n",
       " 'https://en.wikipedia.org/wiki/Massachusetts',\n",
       " 'https://en.wikipedia.org/wiki/Michigan',\n",
       " 'https://en.wikipedia.org/wiki/Minnesota',\n",
       " 'https://en.wikipedia.org/wiki/Mississippi',\n",
       " 'https://en.wikipedia.org/wiki/Missouri',\n",
       " 'https://en.wikipedia.org/wiki/Montana',\n",
       " 'https://en.wikipedia.org/wiki/Nebraska',\n",
       " 'https://en.wikipedia.org/wiki/Nevada',\n",
       " 'https://en.wikipedia.org/wiki/New_Hampshire',\n",
       " 'https://en.wikipedia.org/wiki/New_Jersey',\n",
       " 'https://en.wikipedia.org/wiki/New_Mexico',\n",
       " 'https://en.wikipedia.org/wiki/New_York_(state)',\n",
       " 'https://en.wikipedia.org/wiki/North_Carolina',\n",
       " 'https://en.wikipedia.org/wiki/North_Dakota',\n",
       " 'https://en.wikipedia.org/wiki/Ohio',\n",
       " 'https://en.wikipedia.org/wiki/Oklahoma',\n",
       " 'https://en.wikipedia.org/wiki/Oregon',\n",
       " 'https://en.wikipedia.org/wiki/Pennsylvania',\n",
       " 'https://en.wikipedia.org/wiki/Rhode_Island',\n",
       " 'https://en.wikipedia.org/wiki/South_Carolina',\n",
       " 'https://en.wikipedia.org/wiki/South_Dakota',\n",
       " 'https://en.wikipedia.org/wiki/Tennessee',\n",
       " 'https://en.wikipedia.org/wiki/Texas',\n",
       " 'https://en.wikipedia.org/wiki/Utah',\n",
       " 'https://en.wikipedia.org/wiki/Vermont',\n",
       " 'https://en.wikipedia.org/wiki/Virginia',\n",
       " 'https://en.wikipedia.org/wiki/Washington_(state)',\n",
       " 'https://en.wikipedia.org/wiki/West_Virginia',\n",
       " 'https://en.wikipedia.org/wiki/Wisconsin',\n",
       " 'https://en.wikipedia.org/wiki/Wyoming']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = []\n",
    "for tr in trs[2:]:\n",
    "    th = tr.find(\"th\")\n",
    "    a = th.find(\"a\")\n",
    "    urls.append(\"https://en.wikipedia.org\" + a.attrs[\"href\"])\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alabama\n",
      "Alaska\n",
      "Arizona\n",
      "Arkansas\n",
      "California\n",
      "Colorado\n",
      "Connecticut\n",
      "Delaware\n",
      "Florida\n",
      "Georgia\n",
      "Hawaii\n",
      "Idaho\n",
      "Illinois\n",
      "Indiana\n",
      "Iowa\n",
      "Kansas\n",
      "Kentucky\n",
      "Louisiana\n",
      "Maine\n",
      "Maryland\n",
      "Massachusetts\n",
      "Michigan\n",
      "Minnesota\n",
      "Mississippi\n",
      "Missouri\n",
      "Montana\n",
      "Nebraska\n",
      "Nevada\n",
      "New_Hampshire\n",
      "New_Jersey\n",
      "New_Mexico\n",
      "New_York\n",
      "North_Carolina\n",
      "North_Dakota\n",
      "Ohio\n",
      "Oklahoma\n",
      "Oregon\n",
      "Pennsylvania\n",
      "Rhode_Island\n",
      "South_Carolina\n",
      "South_Dakota\n",
      "Tennessee\n",
      "Texas\n",
      "Utah\n",
      "Vermont\n",
      "Virginia\n",
      "Washington\n",
      "West_Virginia\n",
      "Wisconsin\n",
      "Wyoming\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# STAGE 2: just download the 50 pages\n",
    "for url in urls:\n",
    "    name = url.split(\"/\")[-1]\n",
    "    name = name.split(\"_(\")[0]\n",
    "    print(name)\n",
    "    \n",
    "    path = name+\".html\"\n",
    "    if os.path.exists(path):\n",
    "        continue\n",
    "    \n",
    "    # do the slow part, because we don't have the file\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    \n",
    "    f = open(path, \"w\")\n",
    "    f.write(r.text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE 3: parse the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_state_file(path):\n",
    "    f = open(path)\n",
    "    html = f.read()\n",
    "    f.close()\n",
    "    doc = BeautifulSoup(html, \"html.parser\")\n",
    "    stats = {}\n",
    "    for tr in doc.find_all(\"tr\"):\n",
    "        cells = tr.find_all([\"th\", \"td\"])\n",
    "        if len(cells) != 2:\n",
    "            continue\n",
    "        key = cells[0].get_text()\n",
    "        val = cells[1].get_text()\n",
    "        stats[key] = val\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Madison'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = parse_state_file(\"Wisconsin.html\")\n",
    "stats[\"Capital\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
